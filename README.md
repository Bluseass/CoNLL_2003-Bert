# Проект: Модель BERT для задачи Named Entity Recognition (NER)

## Описание проекта

Этот проект представляет собой пример использования модели BERT для решения задачи Named Entity Recognition (NER). Задача NER заключается в идентификации и классификации именованных сущностей в тексте, таких как имена, места, организации и др.

## Ключевые шаги

1. **Подготовка данных**: Данные загружаются из файлов, содержащих предложения с метками именованных сущностей. Каждое предложение состоит из последовательности слов с соответствующими метками. Функция `load_sentences` выполняет этот процесс.

2. **Подготовка модели BERT**: Используется предварительно обученная модель BERT, предварительно настроенная для задачи классификации токенов. Модель загружается с помощью библиотеки `transformers` и конфигурируется для соответствия количеству меток в нашем наборе данных.

3. **Токенизация**: Предложения токенизируются с использованием токенизатора модели BERT. Каждое слово разбивается на токены, а затем конвертируется в уникальный идентификатор.

4. **Предобработка данных**: Для обучения модели данные должны быть предварительно обработаны. Этот процесс включает токенизацию, преобразование меток в числовые индексы и подготовку массивов для обучения.

5. **Обучение модели**: Модель компилируется с использованием оптимизатора Adam и функции потерь SparseCategoricalCrossentropy. Затем она обучается на обучающем наборе данных с валидацией на валидационном наборе.

6. **Оценка модели**: После обучения модель оценивается на тестовом наборе данных. Оценка включает вычисление потерь и точности модели.

## Результаты

Результаты обучения loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.0213 - val_accuracy: 0.9939, на валидации Loss:0.025, Accuracy:0.995
